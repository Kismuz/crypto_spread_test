{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # suppress h5py deprecation warning\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import backtrader as bt\n",
    "import backtrader.indicators as btind\n",
    "from backtrader import Indicator\n",
    "\n",
    "from gym import spaces\n",
    "from btgym.spaces import DictSpace\n",
    "\n",
    "from btgym import BTgymEnv, BTgymDataset\n",
    "from btgym.strategy.base import BTgymBaseStrategy\n",
    "from btgym.strategy.utils import tanh\n",
    "\n",
    "#from btgym.algorithms import A3C, AacStackedRL2Policy\n",
    "\n",
    "from btgym.strategy.observers import Reward, Position, NormPnL\n",
    "\n",
    "from btgym.research.gps.aac import GuidedAAC\n",
    "from btgym.research.gps.policy import GuidedPolicy_0_0\n",
    "from btgym.research.gps.strategy import GuidedStrategy_0_0, ExpertObserver\n",
    "\n",
    "from btgym.research.casual_conv.networks import conv_1d_casual_encoder, conv_1d_casual_attention_encoder\n",
    "\n",
    "from btgym.algorithms import Launcher\n",
    "\n",
    "from btgym.datafeed.generator import BaseDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "DATA_BIAS = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ou_process(num_points, mu=0, l=1, sigma=1, s0=0, dt=1):\n",
    "    \"\"\"\n",
    "    Generates Ornshtein-Ulenbeck process realisation trajectory:\n",
    "    mu - mean;\n",
    "    l - lambda, mean reversion rate;\n",
    "    sigma - volatility;\n",
    "    s0 - starting point;\n",
    "    dt - time increment;\n",
    "    \"\"\"   \n",
    "    n = num_points\n",
    "    x = np.zeros(n)\n",
    "    x[0] = s0\n",
    "    for i in range(1, n):\n",
    "        x[i] = x[i-1] * np.exp(-l*dt) + mu*(1-np.exp(-l*dt) ) +\\\n",
    "                 sigma*((1-np.exp(-2*l*dt))/2*l)**0.5 * np.random.normal(0, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CryptoSpreadStrat_0(GuidedStrategy_0_0):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    # Hyperparameters for estimating signal features:\n",
    "    features_parameters = [1, 4, 16, 64, 256, 512]\n",
    "    num_features = len(features_parameters)\n",
    "\n",
    "    # Time embedding period:\n",
    "    time_dim = 128 \n",
    "\n",
    "    # Number of environment steps to skip before returning next response,\n",
    "    # e.g. if set to 10 -- agent will interact with environment every 10th step;\n",
    "    # every other step agent action is assumed to be 'hold':\n",
    "    skip_frame = 1\n",
    "\n",
    "    # Number of timesteps reward estimation statistics are averaged over, should be:\n",
    "    # skip_frame_period <= avg_period <= time_embedding_period:\n",
    "    avg_period = 30\n",
    "\n",
    "    # Possible agent actions:\n",
    "    portfolio_actions = ('hold', 'buy', 'sell', 'close')\n",
    "  \n",
    "    params = dict(\n",
    "        # Note: fake `Width` dimension to use 2d conv etc.:\n",
    "        state_shape=\n",
    "            {\n",
    "                'external': spaces.Box(low=-10, high=10, shape=(time_dim, 1, num_features*2), dtype=np.float32),\n",
    "                'internal': spaces.Box(low=-2, high=2, shape=(avg_period, 1, 5), dtype=np.float32),\n",
    "                'expert': spaces.Box(low=0, high=10, shape=(len(portfolio_actions),), dtype=np.float32),\n",
    "                'metadata': DictSpace(\n",
    "                    {\n",
    "                        'type': spaces.Box(\n",
    "                            shape=(),\n",
    "                            low=0,\n",
    "                            high=1,\n",
    "                            dtype=np.uint32\n",
    "                        ),\n",
    "                        'trial_num': spaces.Box(\n",
    "                            shape=(),\n",
    "                            low=0,\n",
    "                            high=10**10,\n",
    "                            dtype=np.uint32\n",
    "                        ),\n",
    "                        'trial_type': spaces.Box(\n",
    "                            shape=(),\n",
    "                            low=0,\n",
    "                            high=1,\n",
    "                            dtype=np.uint32\n",
    "                        ),\n",
    "                        'sample_num': spaces.Box(\n",
    "                            shape=(),\n",
    "                            low=0,\n",
    "                            high=10**10,\n",
    "                            dtype=np.uint32\n",
    "                        ),\n",
    "                        'first_row': spaces.Box(\n",
    "                            shape=(),\n",
    "                            low=0,\n",
    "                            high=10**10,\n",
    "                            dtype=np.uint32\n",
    "                        ),\n",
    "                        'timestamp': spaces.Box(\n",
    "                            shape=(),\n",
    "                            low=0,\n",
    "                            high=np.finfo(np.float64).max,\n",
    "                            dtype=np.float64\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "            },\n",
    "        cash_name='default_cash',\n",
    "        asset_names=['default_asset'],\n",
    "        start_cash=None,\n",
    "        commission=0.0025,\n",
    "        leverage=1.0,\n",
    "        drawdown_call=5,\n",
    "        target_call=19,\n",
    "        portfolio_actions=portfolio_actions,\n",
    "        initial_action=None,\n",
    "        initial_portfolio_action=None,\n",
    "        skip_frame=skip_frame,\n",
    "        state_ext_scale=2e3,\n",
    "        state_int_scale=1.0, \n",
    "        metadata={}\n",
    "    )\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(GuidedStrategy_0_0, self).__init__(**kwargs)\n",
    "        self.data.high = self.data.low = self.data.close = self.data.open\n",
    "        self.current_expert_action = np.asarray([0.51, 0, 0, 0.49])\n",
    "        self.state['metadata'] = self.metadata\n",
    "        self.r_debug = {\n",
    "            'f1': [],\n",
    "            'f2': [],\n",
    "            'f_real_pnl': [],\n",
    "        }\n",
    "    \n",
    "    def nextstart(self):\n",
    "        \"\"\"\n",
    "        Not used.\n",
    "        \"\"\"\n",
    "        # This value shows how much episode records we need to spend\n",
    "        # to estimate first environment observation:\n",
    "        self.inner_embedding = self.data.close.buflen()\n",
    "        self.log.info('Inner time embedding: {}'.format(self.inner_embedding))\n",
    "        self.data.high = self.data.low = self.data.close = self.data.open\n",
    "\n",
    "\n",
    "    def set_datalines(self):\n",
    "        self.data.high = self.data.low = self.data.close = self.data.open\n",
    "        \n",
    "        self.data.features = [\n",
    "            btind.SimpleMovingAverage(self.data.open, period=period) for period in self.features_parameters\n",
    "        ]\n",
    "        \n",
    "        # Bollinger bands for expert:\n",
    "        #self.data.bb = btind.BollingerBands(self.data.open, period=256, devfactor=3)\n",
    "        self.data.bb = btind.BollingerBands(self.data.features[0], period=128, devfactor=2)\n",
    "\n",
    "        self.data.dim_sma = btind.SimpleMovingAverage(\n",
    "            self.datas[0],\n",
    "            period=(np.asarray(self.features_parameters).max() + self.time_dim)\n",
    "        )\n",
    "        self.data.dim_sma.plotinfo.plot = False\n",
    "        \n",
    "        \n",
    "    def get_external_state(self):\n",
    "\n",
    "        x_sma = np.stack(\n",
    "            [\n",
    "                feature.get(size=self.time_dim) for feature in self.data.features\n",
    "            ],\n",
    "            axis=-1\n",
    "        )\n",
    "        # Gradient along features axis:\n",
    "        dx = np.gradient(x_sma, axis=-1) * self.p.state_ext_scale\n",
    "        # Add up: gradient  along time axis:\n",
    "        dx2 = np.gradient(dx, axis=0) * 10\n",
    "        \n",
    "        # In [-1,1]:\n",
    "        #x = tanh(dx)\n",
    "        x = tanh(np.concatenate([dx, dx2], axis=-1))\n",
    "        return x[:, None, :]\n",
    "    \n",
    "    def get_internal_state(self):\n",
    "\n",
    "        x_broker = np.concatenate(\n",
    "            [\n",
    "                np.asarray(self.broker_stat['value'])[..., None],\n",
    "                np.asarray(self.broker_stat['unrealized_pnl'])[..., None],\n",
    "                np.asarray(self.broker_stat['realized_pnl'])[..., None],\n",
    "                np.asarray(self.broker_stat['cash'])[..., None],\n",
    "                np.asarray(self.broker_stat['exposure'])[..., None],\n",
    "            ],\n",
    "            axis=-1\n",
    "        )\n",
    "        x_broker = tanh(np.gradient(x_broker, axis=-1) * self.p.state_int_scale)\n",
    "#         x_broker = np.gradient(x_broker, axis=-1) * self.p.state_int_scale\n",
    "\n",
    "        return x_broker[:, None, :]\n",
    "\n",
    "    def get_reward(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        # All sliding statistics for this step are already updated by get_state().\n",
    "        \n",
    "        # Potential-based shaping function 1:\n",
    "        # based on potential of averaged profit/loss for current opened trade (unrealized p/l):\n",
    "        unrealised_pnl = np.asarray(self.broker_stat['unrealized_pnl'])\n",
    "        current_pos_duration = self.broker_stat['pos_duration'][-1]\n",
    "        \n",
    "        if current_pos_duration == 0: \n",
    "            f1 = 0 \n",
    "        \n",
    "        else:\n",
    "            if current_pos_duration < self.p.skip_frame:\n",
    "                fi_1 = 0\n",
    "                fi_1_prime = np.average(unrealised_pnl[-current_pos_duration:])\n",
    "            \n",
    "            elif current_pos_duration < 2 * self.p.skip_frame:\n",
    "                fi_1 = np.average(\n",
    "                    unrealised_pnl[-(self.p.skip_frame + current_pos_duration):-self.p.skip_frame]\n",
    "                )\n",
    "                fi_1_prime = np.average(unrealised_pnl[-self.p.skip_frame:])\n",
    "                \n",
    "            else:\n",
    "                fi_1 = np.average(\n",
    "                    unrealised_pnl[-2 * self.p.skip_frame:-self.p.skip_frame]\n",
    "                )\n",
    "                fi_1_prime = np.average(unrealised_pnl[-self.p.skip_frame:])\n",
    "                \n",
    "            f1 = self.p.gamma * fi_1_prime - fi_1 \n",
    "#             f1 = np.clip(f1 + 1, a_min=1e-10, a_max=None)\n",
    "#             f1 = np.log(f1)\n",
    "\n",
    "        #print('pos_duration: {}, f1: {}'.format(current_pos_duration, f1))\n",
    "\n",
    "        self.r_debug['f1'].append(f1)\n",
    "        # NOT USED! Potential-based shaping function 2:\n",
    "        # based on potential of averaged broker value, normalized wrt to max drawdown and target bounds.\n",
    "        norm_broker_value = np.asarray(self.broker_stat['value'])\n",
    "\n",
    "        f2 = self.p.gamma * np.average(norm_broker_value[-self.p.skip_frame:]) \\\n",
    "            - np.average(norm_broker_value[- 2 * self.p.skip_frame:-self.p.skip_frame])\n",
    "\n",
    "        self.r_debug['f2'].append(f2)\n",
    "\n",
    "        # Main reward function: normalized realized profit/loss:\n",
    "        realized_pnl = np.asarray(self.broker_stat['realized_pnl'])[-self.p.skip_frame:].sum()\n",
    "        \n",
    "        self.r_debug['f_real_pnl'].append(10 * realized_pnl)\n",
    "\n",
    "        # Weights are subject to tune:\n",
    "        self.reward = (\n",
    "             10.0 * f1 + 10.0 * realized_pnl \n",
    "        ) * self.p.reward_scale\n",
    "\n",
    "        self.reward = np.clip(self.reward, -self.p.reward_scale, self.p.reward_scale)\n",
    "\n",
    "        return self.reward\n",
    "    \n",
    "#     def stop(self):\n",
    "#         \"\"\"\n",
    "#         Service output.\n",
    "#         \"\"\"\n",
    "#         for k, v in self.r_debug.items():\n",
    "#             v = np.asarray(v)\n",
    "            \n",
    "#             print('{}: sum: {}, mean: {}, max: {}, min: {}'.format(k, v.sum(), v.mean(), v.max(), v.min()))\n",
    "\n",
    "    def get_expert_state(self):\n",
    "        \"\"\"\n",
    "        Simple BB logic\n",
    "        \"\"\"\n",
    "        self.current_expert_action = np.asarray([0.51, 0, 0, 0.49])\n",
    "\n",
    "        asset = np.frombuffer(self.data.features[0].get(size=self.p.skip_frame))\n",
    "        bb_top = np.frombuffer(self.data.bb.top.get(size=self.p.skip_frame))\n",
    "        bb_bot = np.frombuffer(self.data.bb.bot.get(size=self.p.skip_frame))\n",
    "        \n",
    "        \n",
    "        if asset.max() > bb_top.max():\n",
    "                # Issue sell:\n",
    "                self.current_expert_action = np.asarray([0, 0, 1, 0])\n",
    "\n",
    "        elif asset.min() < bb_bot.min():\n",
    "                # Issue Buy:\n",
    "                self.current_expert_action = np.asarray([0, 1, 0, 0])\n",
    "\n",
    "        return self.current_expert_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data setup:\n",
    "# filename='./data/CRYPTO_M1_201809_biased_1e-5.csv'\n",
    "\n",
    "parsing_params = dict(\n",
    "    # CSV source specific parsing params:\n",
    "    sep=',',\n",
    "    header=0,\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    names=['open'],\n",
    "    timeframe=1,  # 1 minute.\n",
    "    datetime=0,\n",
    "    open=1,  # only single value used per timestep\n",
    "    high=-1,\n",
    "    low=-1,\n",
    "    close=-1,\n",
    "    volume=-1,\n",
    "    openinterest=-1,\n",
    ")\n",
    "\n",
    "domain = BaseDataGenerator(\n",
    "    generator_fn=ou_process,\n",
    "    generator_params=dict(l=0.05, sigma=2e-7, mu=1e-5, s0=1e-5),\n",
    "    episode_duration=dict(days=4, hours=23, minutes=59),\n",
    ")\n",
    "\n",
    "# Setting up environment core simulation engine:\n",
    "engine = bt.Cerebro()\n",
    "\n",
    "engine.addstrategy(\n",
    "    CryptoSpreadStrat_0,\n",
    "    start_cash=1000,  # initial broker cash\n",
    "    commission=0.0015, # 0.15% broker commission fee\n",
    "    leverage=1,\n",
    "    order_size=200 * DATA_BIAS**-1,  # fixed stake, mind leverage\n",
    "    drawdown_call=10, # max 10% to loose, in percent of initial cash\n",
    "    target_call=10,  # max 10% to win, same\n",
    "    skip_frame=2, \n",
    "    gamma=0.99,  #same as A3C gamma discount factor, used for rewrd shaping\n",
    "    reward_scale=25, #7, # gardient`s nitrox, touch with care!\n",
    "    #state_ext_scale=np.linspace(2e6, 2e7, num=8)  \n",
    "    state_ext_scale=2e7\n",
    ")\n",
    "\n",
    "# Expert actions observer:\n",
    "engine.addobserver(ExpertObserver)\n",
    "\n",
    "# Environment configuration:\n",
    "env_config = dict(\n",
    "    class_ref=BTgymEnv, \n",
    "    kwargs=dict(\n",
    "        dataset=domain,\n",
    "        engine=engine,\n",
    "        render_modes=['episode', 'human', 'internal','external'],\n",
    "        render_state_as_image=True,\n",
    "        render_ylabel='OHL_diff. / Internals',\n",
    "        render_size_episode=(12,8),\n",
    "        render_size_human=(9, 4),\n",
    "        render_size_state=(11, 3),\n",
    "        render_dpi=75,\n",
    "        port=5000,\n",
    "        data_port=4999,\n",
    "        connect_timeout=240,\n",
    "        verbose=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Distributed TF training cluster congfig:\n",
    "cluster_config = dict(\n",
    "    host='127.0.0.1',\n",
    "    port=12230,\n",
    "    num_workers=4,  # set according CPU's available or so\n",
    "    num_ps=1,\n",
    "    num_envs=1,\n",
    "    log_dir=os.path.expanduser('~/tmp/crypto_spread_test_0'),\n",
    ")\n",
    "\n",
    "# Algorithm policy estimator:\n",
    "# policy_config = dict(\n",
    "#     class_ref=GuidedPolicy_0_0,\n",
    "#     kwargs={\n",
    "#         'lstm_layers': (256, 256),\n",
    "#         'lstm_2_init_period': 60,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "policy_config = dict(\n",
    "    class_ref=GuidedPolicy_0_0,\n",
    "    kwargs={\n",
    "        'lstm_layers': (256, 256),\n",
    "        'lstm_2_init_period': 50,\n",
    "        'conv_2d_layer_config': (\n",
    "             (32, (3, 1), (2, 1)),\n",
    "             (32, (3, 1), (2, 1)),\n",
    "             (64, (3, 1), (2, 1)),\n",
    "             (64, (3, 1), (2, 1))\n",
    "         ),\n",
    "        'encode_internal_state': False,\n",
    "        'state_encoder_class_ref': conv_1d_casual_encoder,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Algorithm config:\n",
    "trainer_config = dict(\n",
    "    class_ref=GuidedAAC,\n",
    "    kwargs=dict(\n",
    "        opt_learn_rate=[1e-4, 1e-4], # random log-uniform \n",
    "        opt_end_learn_rate=1e-5,\n",
    "        opt_decay_steps=100*10**6,\n",
    "        model_gamma=0.99,\n",
    "        model_gae_lambda=1.0,\n",
    "        model_beta=0.05, # entropy reg ~0.05\n",
    "        aac_lambda=1.0, # main a3c loss weight\n",
    "        guided_lambda=10.0,  # imitation loss weight\n",
    "        guided_decay_steps=3*10**6,  # annealing guided_lambda to zero in 4M steps\n",
    "        rollout_length=20,\n",
    "        time_flat=True, \n",
    "        episode_train_test_cycle=(1, 0),\n",
    "        model_summary_freq=10,\n",
    "        episode_summary_freq=1,\n",
    "        env_render_freq=5,\n",
    "        #aux_render_modes=['action_prob', 'value_fn'], \n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Putting it all together:\n",
    "launcher = Launcher(\n",
    "    cluster_config=cluster_config,\n",
    "    env_config=env_config,\n",
    "    trainer_config=trainer_config,\n",
    "    policy_config=policy_config,\n",
    "    test_mode=False,\n",
    "    max_env_steps=50*10**6,\n",
    "    root_random_seed=0,\n",
    "    purge_previous=1,  # ask to override previously saved model and logs\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Train it:\n",
    "launcher.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =========="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
